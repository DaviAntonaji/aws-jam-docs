# Task 3: Load Player Reference Data ğŸ‘¥

**Pontos PossÃ­veis:** 45  
**Penalidade de Dica:** 0  
**Pontos DisponÃ­veis:** 45

---

## ğŸ“– Background

Nesta seÃ§Ã£o, vocÃª irÃ¡ carregar dados de jogadores com **diferentes schemas** em uma Ãºnica tabela no Redshift. O tipo de dados **SUPER** do Redshift suporta a persistÃªncia de dados semiestruturados em forma schema-less. VocÃª entÃ£o usarÃ¡ **PartiQL** para consultar os dados semiestruturados com tipagem dinÃ¢mica.

Um cluster Redshift (**playersds**) foi prÃ©-criado para vocÃª na conta.

## ğŸ¯ Sua Tarefa

1. Conectar ao cluster Redshift **playersds**
2. Criar tabela **staging** com coluna tipo **SUPER**
3. Carregar mÃºltiplos arquivos JSON do S3 (cada um com schema diferente)
4. **Unnest** e **unpivot** os dados para tabela final
5. Contar total de jogadores registrados

---

## ğŸ“š Passo a Passo Completo

### STEP 1: Abrir Nova Aba do Query Editor

**Por quÃª:**
- VocÃª jÃ¡ tem uma aba conectada ao **gamesds** (Task 2)
- Precisa de outra aba para **playersds**
- Ter ambas abertas facilitarÃ¡ a Task 4

**AÃ§Ãµes:**
1. **OpÃ§Ã£o A:** Duplicar aba atual do browser (Ctrl+Shift+K ou Cmd+T)
2. **OpÃ§Ã£o B:** Abrir nova janela do Query Editor V2

---

### STEP 2: Conectar ao Players Data Store

**NavegaÃ§Ã£o:**
1. Redshift Query Editor V2
2. **Add connection** ou selecione conexÃ£o existente

**ConfiguraÃ§Ã£o:**
- **Connection type:** Temporary credentials
- **Authentication:** Database user name
- **Cluster:** **playersds** âš ï¸ (nÃ£o gamesds!)
- **Database:** `dev`
- **Database user:** `awsuser`
- Click **Connect**

> âš ï¸ **IMPORTANTE:** Verifique o dropdown do cluster. Deve estar em **playersds**!

---

### STEP 3: Habilitar Case Sensitivity

**Por quÃª necessÃ¡rio:**
Os campos JSON podem ter nomes em upper case ou mixed case. Precisamos configurar o Redshift para reconhecer esses nomes.

```sql
SET enable_case_sensitive_identifier TO true;
```

**Resultado esperado:**
```
SET
```

> ğŸ’¡ **Nota:** Quando os campos JSON estÃ£o em upper/mixed case, vocÃª DEVE:
> 1. Configurar `enable_case_sensitive_identifier` = TRUE
> 2. Envolver campos com aspas duplas: `"FieldName"`

---

### STEP 4: Criar Tabela Staging

**O que Ã© staging:**
Tabela temporÃ¡ria que recebe dados "crus" antes de serem transformados.

**SQL:**

```sql
DROP TABLE IF EXISTS lol_player_stg;

CREATE TABLE lol_player_stg (
  type    VARCHAR,
  version VARCHAR,
  data    SUPER     -- â­ Coluna que armazena JSON de qualquer schema
);
```

**Resultado esperado:**
```
CREATE TABLE
```

**Estrutura:**
- `type` e `version`: Metadados do arquivo JSON
- `data`: Coluna **SUPER** que pode conter qualquer estrutura JSON

---

### STEP 5: Carregar Dados do S3

**Onde encontrar IAM Role ARN:**
- **Output Properties** â†’ **RedshiftGameRoleArn**
- Ou IAM Console â†’ Roles â†’ `Redshiftgamesrole`

**Formato do ARN:**
```
arn:aws:iam::ACCOUNT_ID:role/Redshiftgamesrole
```

#### COPY 1: Champion Info (primeira versÃ£o)

```sql
COPY lol_player_stg 
FROM 's3://redshift-demos/data/players/champion_info.json'
REGION 'us-east-1'
IAM_ROLE 'arn:aws:iam::123456789012:role/Redshiftgamesrole'  -- âš ï¸ Substitua
FORMAT JSON 'auto';
```

**Resultado esperado:**
```
INFO: Load into table 'lol_player_stg' completed, N rows loaded successfully
```

#### COPY 2: Champion Info (segunda versÃ£o)

```sql
COPY lol_player_stg 
FROM 's3://redshift-demos/data/players/champion_info_2.json'
REGION 'us-east-1'
IAM_ROLE 'arn:aws:iam::123456789012:role/Redshiftgamesrole'  -- âš ï¸ Substitua
FORMAT JSON 'auto';
```

#### COPY 3: Summoner Spell Info

```sql
COPY lol_player_stg 
FROM 's3://redshift-demos/data/players/summoner_spell_info.json'
REGION 'us-east-1'
IAM_ROLE 'arn:aws:iam::123456789012:role/Redshiftgamesrole'  -- âš ï¸ Substitua
FORMAT JSON 'auto';
```

**Verificar dados carregados:**

```sql
SELECT 
  type,
  version,
  COUNT(*) AS record_count
FROM lol_player_stg
GROUP BY type, version;
```

**Resultado esperado:**
```
type     | version | record_count
---------|---------|-------------
champion | 9.3.1   | 143
champion | 10.5.1  | 148
summoner | 9.3.1   | 14
```

**Ver estrutura dos dados:**

```sql
SELECT type, version, data 
FROM lol_player_stg 
LIMIT 3;
```

---

### STEP 6: Unnest e Criar Tabela Final

**O que este SQL faz:**
1. **Unnest:** Expande o objeto JSON da coluna `data`
2. **Unpivot:** Transforma chaves do JSON em linhas
3. **Cast:** Converte campos SUPER para tipos tradicionais (INT, VARCHAR)
4. **Create + Insert:** Cria tabela final e jÃ¡ popula com dados transformados

**SQL completo:**

```sql
CREATE TABLE lol_players
DISTKEY (id)
SORTKEY AUTO
AS
SELECT
  type,
  version,
  value.id::int                   AS id,
  value.title::varchar            AS title,
  value.name::varchar             AS name,
  value.key::varchar              AS key,
  value.description::varchar      AS description,
  value.summonerLevel::int        AS summoner_level,
  value.tags                      AS tags    -- MantÃ©m como SUPER
FROM 
  lol_player_stg c,
  UNPIVOT c.data AS value AT key;
```

**Resultado esperado:**
```
SELECT INTO
```

**ExplicaÃ§Ã£o linha por linha:**

| Elemento | FunÃ§Ã£o |
|----------|---------|
| `CREATE TABLE ... AS` | Cria tabela e popula em uma operaÃ§Ã£o |
| `DISTKEY (id)` | Distribui dados por ID entre nodes |
| `SORTKEY AUTO` | Redshift escolhe melhor sort key automaticamente |
| `FROM lol_player_stg c` | Tabela staging como fonte |
| `UNPIVOT c.data AS value AT key` | Transforma objeto JSON em linhas |
| `value.id::int` | Extrai campo `id` e converte para INT |
| `value.title::varchar` | Extrai campo `title` como VARCHAR |
| `value.tags` | MantÃ©m campo `tags` como SUPER (array) |

**UNPIVOT visual:**

```
Antes (1 linha):
{
  "Ahri": {"id": 103, "name": "Ahri", "title": "the Nine-Tailed Fox"},
  "Zed": {"id": 238, "name": "Zed", "title": "the Master of Shadows"}
}

Depois (2 linhas):
key   | value
------|----------------------------------------
Ahri  | {"id": 103, "name": "Ahri", ...}
Zed   | {"id": 238, "name": "Zed", ...}
```

---

### STEP 7: Consultar Dados Parseados

**Ver primeiras linhas:**

```sql
SELECT * 
FROM lol_players 
ORDER BY type, id 
LIMIT 20;
```

**Resultado esperado:**
```
type     | version | id  | title               | name    | key  | description
---------|---------|-----|---------------------|---------|------|-------------
champion | 9.3.1   | 1   | the Dark Child      | Annie   | 1    | Wielding...
champion | 9.3.1   | 2   | the Berserker       | Olaf    | 2    | Olaf is...
champion | 9.3.1   | 3   | the Twisted Fate    | Twisted | 4    | Twisted...
```

**Contagem total de registros:**

```sql
SELECT COUNT(*) AS total_rows 
FROM lol_players;
```

**Contagem por tipo:**

```sql
SELECT 
  type,
  COUNT(*) AS count
FROM lol_players
GROUP BY type;
```

---

## âœ… ValidaÃ§Ã£o da Tarefa

**Challenge Question:**
```
What is the total count of players registered to the game?
```

**SQL para obter a resposta:**

```sql
SELECT COUNT(DISTINCT id) AS total_players
FROM lol_players
WHERE id IS NOT NULL;
```

**Por que usar DISTINCT id?**

O desafio pergunta por "players registered", nÃ£o por "linhas na tabela". Como vocÃª carregou mÃºltiplas versÃµes de dados do mesmo jogo, alguns IDs podem aparecer em diferentes versÃµes.

**Contagem correta:**
- Usa `COUNT(DISTINCT id)` para contar IDs Ãºnicos
- Filtra `id IS NOT NULL` para excluir possÃ­veis nulos

**Resultado esperado:**
```
total_players
-------------
XXX
```

> **ğŸ“ Este nÃºmero Ã© a resposta que vocÃª deve submeter**

---

## ğŸ” Troubleshooting

### Problema: COPY falha com erro de permissÃ£o

**Erro:**
```
ERROR: S3ServiceException: Access Denied
```

**Causas possÃ­veis:**
- IAM Role ARN incorreto
- Role nÃ£o tem permissÃµes S3
- Bucket ou caminho incorreto

**SoluÃ§Ã£o:**

```sql
-- Verificar ARN exato nas Output Properties
-- O ARN deve estar completo:
'arn:aws:iam::123456789012:role/Redshiftgamesrole'

-- Verificar se bucket existe (use exatamente este caminho):
's3://redshift-demos/data/players/champion_info.json'
```

### Problema: UNPIVOT nÃ£o funciona

**Erro:**
```
ERROR: syntax error at or near "UNPIVOT"
```

**Causa:**
- Redshift versÃ£o muito antiga (nÃ£o Ã© o caso no lab)
- Syntax error no SQL

**SoluÃ§Ã£o:**

```sql
-- Sintaxe correta do UNPIVOT:
FROM table_name,
UNPIVOT column_name AS value_alias AT key_alias
```

### Problema: Contagem retorna valor errado

**Sintomas:**
- Contagem muito alta (conta versÃµes duplicadas)

**SoluÃ§Ã£o:**

```sql
-- âŒ Errado:
SELECT COUNT(*) FROM lol_players;  -- Conta todas as linhas

-- âœ… Correto:
SELECT COUNT(DISTINCT id) FROM lol_players;  -- Conta IDs Ãºnicos
```

### Problema: Conectado ao cluster errado

**Sintomas:**
- Tabelas nÃ£o aparecem
- Erro "table does not exist"

**SoluÃ§Ã£o:**
1. Verifique dropdown do cluster no Query Editor
2. Deve estar em **playersds** (nÃ£o gamesds)
3. Se estiver errado, reconecte ao cluster correto

---

## ğŸ’¡ Dicas Importantes

### 1. DiferenÃ§as entre Clusters

**gamesds:**
- Dados de streaming (hot data)
- Materialized Views
- Dados de sessÃµes de jogos

**playersds:**
- Dados de referÃªncia (cold data)
- Carregados do S3
- Dados de jogadores

### 2. SUPER vs Tipos Tradicionais

**Quando usar SUPER:**
- Schema varia entre registros
- Dados aninhados complexos
- Precisa armazenar JSON "as is"

**Quando converter para tipos tradicionais:**
- Queries mais frequentes
- Performance crÃ­tica
- Schema estÃ¡vel

### 3. FORMAT JSON 'auto'

**O que faz:**
- Detecta schema automaticamente
- Mapeia campos JSON para colunas
- Se nÃ£o houver colunas correspondentes, usa SUPER

**Alternativas:**
```sql
FORMAT JSON 's3://bucket/jsonpaths.json'  -- Schema explÃ­cito
FORMAT JSON 'auto ignorecase'             -- Ignora case nos nomes
```

### 4. DISTKEY e SORTKEY

**DISTKEY:**
- Distribui dados entre nodes do cluster
- Use em colunas de JOIN frequentes

**SORTKEY AUTO:**
- Redshift escolhe automaticamente
- Baseado em padrÃµes de query

### 5. Monitore Carga

```sql
-- Ver Ãºltimas cargas
SELECT * FROM stl_load_errors 
ORDER BY starttime DESC 
LIMIT 10;

-- Ver estatÃ­sticas de tabela
SELECT 
  "table",
  size,
  tbl_rows
FROM svv_table_info
WHERE "table" = 'lol_players';
```

---

## ğŸ“ Conceitos Aprendidos

### 1. Staging Tables

**PadrÃ£o:**
```
RAW (S3) â†’ STAGING (Redshift SUPER) â†’ FINAL (Redshift typed)
```

**BenefÃ­cios:**
- Valida dados antes de processar
- Permite reprocessamento
- Separa ingestÃ£o de transformaÃ§Ã£o

### 2. SUPER Data Type

**Capacidades:**
- Armazena JSON, array, struct
- Schema flexÃ­vel
- Suporta PartiQL
- IndexÃ¡vel

**Limites:**
- Max 16 MB por valor
- Performance menor que colunas tipadas para queries frequentes

### 3. UNPIVOT

**Transforma:**
```sql
-- De: colunas â†’ linhas
SELECT col1, col2, col3 FROM table;

-- Para: key-value pairs
SELECT key, value FROM table UNPIVOT ...;
```

**Casos de uso:**
- JSON com chaves dinÃ¢micas
- NormalizaÃ§Ã£o de dados wide
- TransformaÃ§Ã£o de formato

### 4. PartiQL

**SQL + JSON:**
```sql
-- Dot notation
SELECT data.field FROM table;

-- Array access
SELECT data[0] FROM table;

-- Nested access
SELECT data.nested.field FROM table;
```

### 5. COPY Command

**Performance:**
- Paralelo e otimizado
- CompressÃ£o automÃ¡tica
- Carrega de mÃºltiplos arquivos

**OpÃ§Ãµes importantes:**
```sql
COPY table FROM 's3://...'
IAM_ROLE '...'
REGION '...'
FORMAT JSON 'auto'
COMPUPDATE ON         -- Atualiza colunas de compressÃ£o
STATUPDATE ON         -- Atualiza estatÃ­sticas
MAXERROR 10;          -- Permite atÃ© 10 erros
```

---

## ğŸ¯ Checklist de ConclusÃ£o

- [ ] Nova aba do Query Editor aberta
- [ ] Conectado ao cluster playersds
- [ ] Database dev selecionado
- [ ] Case sensitivity habilitado
- [ ] Tabela staging lol_player_stg criada
- [ ] IAM Role ARN obtido
- [ ] TrÃªs arquivos JSON carregados via COPY
- [ ] Dados visÃ­veis na staging table
- [ ] Tabela final lol_players criada com UNPIVOT
- [ ] Dados parsed visÃ­veis
- [ ] COUNT(DISTINCT id) executado
- [ ] Total de players identificado
- [ ] Resposta submetida
- [ ] Task 3 validada com sucesso

---

**âœ… PrÃ³xima etapa:** Task 4 - Compartilhar dados entre clusters (âš ï¸ problema de permissÃµes)

> **ğŸ’¡ Conceito-chave aprendido:** O tipo **SUPER** permite carregar mÃºltiplos schemas JSON em uma Ãºnica tabela, que podem entÃ£o ser unnested e convertidos para tipos tradicionais conforme necessÃ¡rio. Isso oferece flexibilidade mÃ¡xima para dados semiestruturados.
